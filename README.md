# Hands_on_projects

✅ Machine Learning & AI Skills
Experience in end-to-end machine learning model development, training, and deployment. (10+ years)

Hands-on work in deep learning including CNNs, RNNs, LSTMs, and GANs for image, audio, and video processing. (9+ years)

Proficient in Natural Language Processing (NLP) tasks like classification, summarization, entity recognition, and intent extraction. (5+ years)

Worked extensively with Large Language Models (LLMs) such as GPT-3, LLaMA2, Mistral, T5, Gemini, and BERT. (5+ years)

Expertise in computer vision applications like segmentation, object detection, deblurring, and OCR using YOLOv5, DeepLabV3+, EfficientNet. (6+ years)

Applied machine learning models for time series forecasting and predictive analytics. (4+ years)

Hands-on implementation of reinforcement learning in LLM-based systems for adaptive feedback. (3+ years)

Experience in designing optimized prompts and task-specific instructions for LLMs. (3+ years)

✅ Cloud Platforms & Deployment
Experience deploying machine learning pipelines on AWS SageMaker, EC2, S3, and API Gateway. (6+ years)

Built and served ML solutions using Google Cloud’s Vertex AI and BigQuery. (5+ years)

Developed intelligent applications using Azure AI services including OpenAI, Azure Search, and AKS. (5+ years)

Trained generative and vision models using A100 GPU clusters for high-performance workloads. (2+ years)

✅ MLOps, CI/CD, and Testing
Implemented robust MLOps pipelines using MLflow, Docker, and Jenkins/GitLab CI/CD workflows. (5+ years)

Used Kubernetes (AKS, GKE) for scalable orchestration and deployment of containerized ML models. (4+ years)

Wrote automated unit, integration, and smoke tests using Pytest for APIs and pipelines. (4+ years)

Built real-time model monitoring dashboards and feedback loops using custom evaluation metrics. (3+ years)

✅ Data Engineering & SQL
Proficient in SQL, PostgreSQL, and MySQL for querying, preprocessing, and transforming structured data. (7+ years)

Built distributed data pipelines using PySpark and Spark SQL in Databricks for model readiness. (4+ years)

Performed extensive data cleaning, transformation, and feature engineering for structured and unstructured data. (9+ years)

Used vector databases like Pinecone and Elasticsearch for semantic search and hybrid RAG systems. (3+ years)

✅ Software Development & API Integration
Strong programming experience in Python for building ML models, APIs, and data pipelines. (10+ years)

Developed and deployed REST APIs using FastAPI and Flask for model integration. (6+ years)

Applied C++ and MATLAB for algorithm prototyping and simulation tasks in earlier academic and R&D work. (3–5 years)

Collaborated using Git, GitHub, and GitLab for version control, code reviews, and branching strategies. (8+ years)

✅ Tools & Frameworks
Worked with TensorFlow, Keras, and PyTorch for building and optimizing deep learning models. (7+ years)

Applied Hugging Face Transformers for NLP, text classification, summarization, and RAG-based applications. (5+ years)

Built intelligent LLM workflows using LangChain and LlamaIndex for chaining prompts and search queries. (3+ years)

Used Tableau, Power BI, Seaborn, and Matplotlib for interactive data visualizations and dashboards. (6+ years)

Integrated Elasticsearch for fuzzy, multi-match, and suggestive NLP-based search in web applications. (3+ years)

Soft Skillset:

Proficient in software development lifecycle, including design, development, testing, and deployment.

Skilled in writing clean, modular, and maintainable code using Python.

Strong debugging and problem-solving skills in real-world AI/ML applications.

Good at designing and testing APIs using FastAPI, Flask, Postman, and Pytest.

Capable of handling multiple priorities in fast-paced, collaborative environments.

Experience integrating ML models with production-grade systems through RESTful APIs.

Comfortable working with agile teams using tools like Jira, Confluence, and Git.

Adept at translating business requirements into scalable machine learning solutions.

Good at documenting models, APIs, and workflows for better team collaboration.

Confident in presenting technical ideas to both technical and non-technical stakeholders.

Focused on delivering high-quality results with attention to detail.

Capable of adapting quickly to new tools, frameworks, and evolving project goals.

Strong understanding of testing strategies to ensure reliable code and reproducible experiments.

Committed to writing testable code with good logging and exception handling practices.

Comfortable leading peer code reviews and suggesting improvements.

Good communicator and collaborator in cross-functional teams involving data scientists, engineers, and business analysts.

Experienced in deploying ML models in real-time and batch environments.

Skilled in optimizing performance of data pipelines and inference systems.

Ability to mentor juniors and support knowledge sharing within teams.

Open to feedback and always looking to improve code quality and delivery timelines.

Good at handling version control and resolving merge conflicts effectively.

Committed to continuous learning and staying updated with latest AI/ML trends.

Professional Experience Highlights
Developed and deployed predictive ML models using PyTorch and TensorFlow for diverse use cases including fraud detection, churn prediction, and document classification.

Built a DeepLabV3+ based semantic segmentation model on Vertex AI for bird sound denoising, achieving a high IoU and F1-score.

Designed and trained a PyTorch model on AWS SageMaker for point-based medical image analysis with 85%+ VHS score accuracy.

Created a Dense Passage Retrieval pipeline using fine-tuned LLaMA2/Mistral models to enhance document retrieval relevance.

Built a custom generative AI pipeline using MusicGen and Mustango models for text-to-music generation tasks on A100 GPUs.

Developed an intelligent document processing system using Azure AI Search and Azure OpenAI for real-time classification and analysis.

Fine-tuned LLMs for text summarization from Electronic Health Records (EHRs), leveraging Hugging Face and GPT-based models.

Built NeoBot, an LLM-powered customer support chatbot with retrieval-augmented generation (RAG) and hybrid semantic search.

Designed a multi-output disease classification system on Vertex AI using EfficientNet-b6 and achieved high F1-score.

Developed a GAN-based model for image super-resolution, significantly improving PSNR and SSIM for blurry inputs.

Deployed an HR Chatbot using RASA integrated with employee portals and mobile applications.

Built an intelligent search engine using Elasticsearch with fuzzy matching, n-gram analysis, and spell-check APIs.

Developed an ML-based lead scoring system for an ed-tech client to prioritize conversions based on user behavior data.

Created a telecom churn prediction model using XGBoost and SMOTE, improving customer retention strategy effectiveness.

Implemented a real-time model monitoring and feedback loop using SageMaker pipelines and Docker containers.

Delivered object detection and organ segmentation solutions using YOLO, U-Net, and custom CNN models in healthcare applications.

Mentored 10+ student teams in deep learning research projects on Alzheimer detection, lung analysis, and satellite data extraction.

Won 1st prize in IEEE-ICETCI competition with a DeepLabV3+ based solution for electrical substation feature extraction from satellite data.

Designed feature engineering pipelines and model training for customer segmentation in financial datasets.

Conducted hyperparameter tuning experiments and ablation studies on NLP models to optimize classification performance.

Built scalable data pipelines using PySpark and Databricks for data ingestion, transformation, and ML preprocessing.

Led API development and testing for ML model endpoints using Flask, FastAPI, and Postman.

Deployed models using Docker, Kubernetes (AKS/GKE), and GitLab CI/CD for continuous delivery.

Used SHAP and interpretability tools to explain model outputs to stakeholders and enhance trust in ML decisions.

Built MLOps workflows with MLflow, Jenkins, and model versioning for tracking experiments and deployments.

Integrated cloud-native services from AWS, GCP, and Azure to build and manage ML infrastructure end-to-end.

Researched cutting-edge generative AI models (e.g., Maxim, Vtoonify) for creative tasks such as style transfer and video generation.

Extracted structured data from documents using YOLOv5 and pytesseract, achieving over 96% recall in classification.

Conducted extensive experiments comparing generative model performance using metrics like CLAP Score, ROUGE, BLEU, and NDCG.

Collaborated with cross-functional teams including product managers, DevOps, and business analysts for project alignment and deployment.

Automated model testing and feedback logging systems for deployed LLMs in production environments.

Managed cloud resources and GPU allocations (A100, V100) for distributed training and cost-efficient experimentation.

* Name of Background check vendor: FADV/USAFact
* BGC order number # 349010219/306483900/4158193/4174349
* Drug Test completion date/ panel type: 01/30/2025
* Did the candidate complete the drug screen with favorable results? Yes